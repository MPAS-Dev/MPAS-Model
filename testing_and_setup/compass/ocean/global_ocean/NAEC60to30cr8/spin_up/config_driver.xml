<driver_script name="run_test.py">
	<case name="spin_up1">
		<step executable="./run.py" quiet="true" pre_message=" * Running spin_up1" post_message=" - Complete"/>
	</case>
	<case name="spin_up2">
		<step executable="./run.py" quiet="true" pre_message=" * Running spin_up2" post_message=" - Complete"/>
	</case>
	<case name="spin_up3">
		<step executable="./run.py" quiet="true" pre_message=" * Running spin_up3" post_message=" - Complete"/>
	</case>
	<case name="spin_up4">
		<step executable="./run.py" quiet="true" pre_message=" * Running spin_up4" post_message=" - Complete"/>
	</case>
	<case name="spin_up5">
		<step executable="./run.py" quiet="true" pre_message=" * Running spin_up5" post_message=" - Complete"/>
	</case>
	<case name="spin_up6">
		<step executable="./run.py" quiet="true" pre_message=" * Running spin_up6" post_message=" - Complete"/>
	</case>
	<case name="test_final_settings">
		<step executable="./run.py" quiet="true" pre_message=" * Running test_final_settings" post_message=" - Complete"/>
	</case>
	<validation>
		<compare_fields file1="test_final_settings/output.nc">
			<template file="prognostic_comparison.xml" path_base="script_core_dir" path="templates/validations"/>
		</compare_fields>
	</validation>
</driver_script>
